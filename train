#!/usr/bin/env python

import argparse
import os
import sys

import torch
import torch.optim as optim
import torch.optim.lr_scheduler as lr_scheduler
import torch.nn as nn
from torch.autograd import Variable

import torchvision
import torchvision.datasets as datasets
import torchvision.transforms as transforms

# from tensorboard_logger import configure, log_value

from models import Generator, Discriminator, FeatureExtractor
from utils import Visualizer, TrainDatasetFromFolder

params = {}
params['trainData'] = 'data/train'
params['workers'] = 2
params['batchSize'] = 16
params['imageSize'] = (210, 318)
params['upSampling'] = 2
params['sizeLimitFactor'] = 2
params['nEpochs'] = 100
params['generatorLR'] = 0.0001
params['discriminatorLR'] = 0.0001
params['cuda'] = True
params['nGPU'] = 1
params['cropSize'] = 0


# parser = argparse.ArgumentParser()
# parser.add_argument('--dataset', type=str, default='cifar100', help='cifar10 | cifar100 | folder')
# parser.add_argument('--dataroot', type=str, default='./data', help='path to dataset')
# parser.add_argument('--workers', type=int, default=2, help='number of data loading workers')
# parser.add_argument('--batchSize', type=int, default=16, help='input batch size')
# parser.add_argument('--imageSize', type=int, default=15, help='the low resolution image size')
# parser.add_argument('--upSampling', type=int, default=2, help='low to high resolution scaling factor')
# parser.add_argument('--nEpochs', type=int, default=100, help='number of epochs to train for')
# parser.add_argument('--generatorLR', type=float, default=0.0001, help='learning rate for generator')
# parser.add_argument('--discriminatorLR', type=float, default=0.0001, help='learning rate for discriminator')
# parser.add_argument('--cuda', action='store_true', help='enables cuda')
# parser.add_argument('--nGPU', type=int, default=1, help='number of GPUs to use')
# parser.add_argument('--generatorWeights', type=str, default='', help="path to generator weights (to continue training)")
# parser.add_argument('--discriminatorWeights', type=str, default='', help="path to discriminator weights (to continue training)")
# parser.add_argument('--out', type=str, default='checkpoints', help='folder to output model checkpoints')


# opt = parser.parse_args()
# print(opt)
#
# try:
#     os.makedirs(opt.out)
# except OSError:
#     pass

if torch.cuda.is_available() and not params['cuda']:
    print("WARNING: You have a CUDA device, so you should probably run with --cuda")

train_set = TrainDatasetFromFolder(params['trainData'], crop_size=params['cropSize'],
                                   upscale_factor=params['upSampling'], size_limit_factor=params['sizeLimitFactor'])

dataloader = torch.utils.data.DataLoader(train_set, batch_size=params['batchSize'],
                                         shuffle=True, num_workers=int(params['workers']))

generator = Generator(1, params['upSampling'])
# if opt.generatorWeights != '':
#     generator.load_state_dict(torch.load(opt.generatorWeights))
# print generator

discriminator = Discriminator()
# if opt.discriminatorWeights != '':
#     discriminator.load_state_dict(torch.load(opt.discriminatorWeights))
# print discriminator

print('# generator parameters:', sum(param.numel() for param in generator.parameters()))
print('# discriminator parameters:', sum(param.numel() for param in discriminator.parameters()))

# For the content loss
feature_extractor = FeatureExtractor(torchvision.models.vgg19(pretrained=True))
# print feature_extractor
content_criterion = nn.MSELoss()
adversarial_criterion = nn.BCELoss()

ones_const = Variable(torch.ones(params['batchSize'], 1))

# if gpu is to be used
if params['cuda']:
    generator.cuda()
    discriminator.cuda()
    feature_extractor.cuda()
    content_criterion.cuda()
    adversarial_criterion.cuda()
    ones_const = ones_const.cuda()

optim_generator = optim.Adam(generator.parameters(), lr=params['generatorLR'])
optim_discriminator = optim.Adam(discriminator.parameters(), lr=params['discriminatorLR'])

# configure('logs/' + opt.dataset + '-' + str(params['batchSize']) + '-' + str(params['generatorLR']) + '-' + str(params['discriminatorLR']), flush_secs=5)
# visualizer = Visualizer(image_size=opt.imageSize*opt.upSampling)

low_res = torch.FloatTensor(params['batchSize'], 1, params['imageSize'][0], params['imageSize'][1])

# Pre-train generator using raw MSE loss
print 'Generator pre-training'
for epoch in range(2):
    mean_generator_content_loss = 0.0

    for i, data in enumerate(dataloader):
        # Generate data
        low_res = data[0]
        high_res_real = data[1]

        # Generate real and fake inputs
        if params['cuda']:
            high_res_real = Variable(high_res_real.cuda())
            high_res_fake = generator(Variable(low_res).cuda())
        else:
            high_res_real = Variable(high_res_real)
            high_res_fake = generator(Variable(low_res))

        ######### Train generator #########
        generator.zero_grad()

        generator_content_loss = content_criterion(high_res_fake, high_res_real)
        mean_generator_content_loss += generator_content_loss.data[0]

        generator_content_loss.backward()
        optim_generator.step()

        ######### Status and display #########
        sys.stdout.write('\r[%d/%d][%d/%d] Generator_MSE_Loss: %.4f' % (epoch, 2, i, len(dataloader), generator_content_loss.data[0]))
        # visualizer.show(low_res, high_res_real.cpu().data, high_res_fake.cpu().data)

    sys.stdout.write('\r[%d/%d][%d/%d] Generator_MSE_Loss: %.4f\n' % (epoch, 2, i, len(dataloader), mean_generator_content_loss/len(dataloader)))
    # log_value('generator_mse_loss', mean_generator_content_loss/len(dataloader), epoch)

# Do checkpointing
torch.save(generator.state_dict(), '%s/generator_pretrain.pth' % '.')

# SRGAN training
optim_generator = optim.Adam(generator.parameters(), lr=params['generatorLR']*0.1)
optim_discriminator = optim.Adam(discriminator.parameters(), lr=params['discriminatorLR']*0.1)

print 'SRGAN training'
for epoch in range(params['nEpochs']):
    mean_generator_content_loss = 0.0
    mean_generator_adversarial_loss = 0.0
    mean_generator_total_loss = 0.0
    mean_discriminator_loss = 0.0

    for i, data in enumerate(dataloader):
        # Generate data
        low_res = data[0]
        high_res_real = data[1]

        # Generate real and fake inputs
        if params['cuda']:
            high_res_real = Variable(high_res_real.cuda())
            high_res_fake = generator(Variable(low_res).cuda())
            target_real = Variable(torch.rand(params['batchSize'],1)*0.5 + 0.7).cuda()
            target_fake = Variable(torch.rand(params['batchSize'],1)*0.3).cuda()
        else:
            high_res_real = Variable(high_res_real)
            high_res_fake = generator(Variable(low_res))
            target_real = Variable(torch.rand(params['batchSize'],1)*0.5 + 0.7)
            target_fake = Variable(torch.rand(params['batchSize'],1)*0.3)
        
        ######### Train discriminator #########
        discriminator.zero_grad()

        discriminator_loss = adversarial_criterion(discriminator(high_res_real), target_real) + \
                             adversarial_criterion(discriminator(Variable(high_res_fake.data)), target_fake)
        mean_discriminator_loss += discriminator_loss.data[0]
        
        discriminator_loss.backward()
        optim_discriminator.step()

        ######### Train generator #########
        generator.zero_grad()

        # duplicate image for rgb
        high_res_real_rgb = transforms.Lambda(lambda x: torch.cat([x, x, x], 1))(high_res_real)
        high_res_fake_rgb = transforms.Lambda(lambda x: torch.cat([x, x, x], 1))(high_res_fake)

        real_features = Variable(feature_extractor(high_res_real_rgb).data)
        fake_features = feature_extractor(high_res_fake_rgb)

        generator_content_loss = content_criterion(high_res_fake, high_res_real) + 0.006*content_criterion(fake_features, real_features)
        mean_generator_content_loss += generator_content_loss.data[0]
        generator_adversarial_loss = adversarial_criterion(discriminator(high_res_fake), ones_const)
        mean_generator_adversarial_loss += generator_adversarial_loss.data[0]

        generator_total_loss = generator_content_loss + 1e-3*generator_adversarial_loss
        mean_generator_total_loss += generator_total_loss.data[0]
        
        generator_total_loss.backward()
        optim_generator.step()   
        
        ######### Status and display #########
        sys.stdout.write('\r[%d/%d][%d/%d] Discriminator_Loss: %.4f Generator_Loss (Content/Advers/Total): %.4f/%.4f/%.4f' % (epoch, params['nEpochs'], i, len(dataloader),
        discriminator_loss.data[0], generator_content_loss.data[0], generator_adversarial_loss.data[0], generator_total_loss.data[0]))
        # visualizer.show(low_res, high_res_real.cpu().data, high_res_fake.cpu().data)

    sys.stdout.write('\r[%d/%d][%d/%d] Discriminator_Loss: %.4f Generator_Loss (Content/Advers/Total): %.4f/%.4f/%.4f\n' % (epoch, params['nEpochs'], i, len(dataloader),
    mean_discriminator_loss/len(dataloader), mean_generator_content_loss/len(dataloader), 
    mean_generator_adversarial_loss/len(dataloader), mean_generator_total_loss/len(dataloader)))

    # log_value('generator_content_loss', mean_generator_content_loss/len(dataloader), epoch)
    # log_value('generator_adversarial_loss', mean_generator_adversarial_loss/len(dataloader), epoch)
    # log_value('generator_total_loss', mean_generator_total_loss/len(dataloader), epoch)
    # log_value('discriminator_loss', mean_discriminator_loss/len(dataloader), epoch)

    # Do checkpointing
    torch.save(generator.state_dict(), '%s/generator_final.pth' % '.')
    torch.save(discriminator.state_dict(), '%s/discriminator_final.pth' % '.')

# Avoid closing
while True:
    pass
